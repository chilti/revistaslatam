# PrecÃ¡lculo de MÃ©tricas - Versiones Disponibles

## ğŸ“Š Versiones del Script

### 1. `precompute_metrics.py` - VersiÃ³n EstÃ¡ndar (Chunk-based)

**Uso recomendado**: Computadoras con RAM limitada (< 16 GB)

**CaracterÃ­sticas**:
- âœ… Procesa datos en chunks (50,000 filas a la vez)
- âœ… Uso mÃ­nimo de RAM (~500 MB)
- âœ… Funciona en cualquier mÃ¡quina
- â±ï¸ Tiempo estimado: 2-4 horas para dataset completo

**EjecuciÃ³n**:
```bash
python precompute_metrics.py
```

---

### 2. `precompute_metrics_parallel.py` - VersiÃ³n Paralela (RAM-optimized)

**Uso recomendado**: Servidores con mucha RAM (> 32 GB) y mÃºltiples nÃºcleos

**CaracterÃ­sticas**:
- âœ… Carga TODO el dataset a RAM (una sola vez)
- âœ… Paraleliza por paÃ­s y revista usando todos los nÃºcleos
- âœ… Speedup: 10-20x mÃ¡s rÃ¡pido
- âš¡ Tiempo estimado: 10-30 minutos para dataset completo

**Requisitos**:
- RAM: ~8-10 GB disponibles (para dataset de 3.7 GB)
- CPU: MÃºltiples nÃºcleos (aprovecha todos los disponibles)

**EjecuciÃ³n**:
```bash
python precompute_metrics_parallel.py
```

**Salida esperada**:
```
ğŸ–¥ï¸  Detected 16 CPU cores
âš™ï¸  Loading data to RAM...
  â†’ Loading journals...
    âœ“ 1,234 journals loaded
  â†’ Loading works (this may take a minute)...
    âœ“ 702,641 works loaded
  âœ“ Data loaded in 45.2 seconds

ğŸ“Š LATAM metrics...
  âœ“ LATAM metrics completed in 12.3s

ğŸ“Š Country metrics (using 16 cores)...
  Processing 19 countries in parallel...
  âœ“ Country metrics completed in 34.5s

ğŸ“Š Journal metrics (using 16 cores)...
  Processing 1,234 journals in parallel...
  âœ“ Journal metrics completed in 156.7s

âœ… ALL METRICS COMPUTED SUCCESSFULLY!
Total time: 248.7s (4.1 minutes)
Speedup: ~16x faster than sequential processing
```

---

### 3. `precompute_country_metrics.py` - Solo PaÃ­ses

**Uso recomendado**: Testing rÃ¡pido o cuando solo necesitas mÃ©tricas de paÃ­ses

**CaracterÃ­sticas**:
- âœ… Solo calcula mÃ©tricas de paÃ­ses (no journals individuales)
- âœ… Mucho mÃ¡s rÃ¡pido que el completo
- â±ï¸ Tiempo estimado: 30-60 minutos

**EjecuciÃ³n**:
```bash
python precompute_country_metrics.py
```

---

## ğŸ¯ Â¿CuÃ¡l usar?

### En tu servidor (128 GB RAM, mÃºltiples nÃºcleos):
```bash
python precompute_metrics_parallel.py
```
**RazÃ³n**: Aprovecha toda la RAM y nÃºcleos disponibles. SerÃ¡ 10-20x mÃ¡s rÃ¡pido.

### En laptop/PC local (< 16 GB RAM):
```bash
python precompute_metrics.py
```
**RazÃ³n**: Usa chunks para no saturar la memoria.

### Para testing rÃ¡pido:
```bash
python precompute_country_metrics.py
```
**RazÃ³n**: Solo paÃ­ses, mucho mÃ¡s rÃ¡pido.

---

## ğŸ“ Archivos Generados

Todos los scripts generan los mismos archivos en `data/cache/`:

```
data/cache/
â”œâ”€â”€ metrics_latam_annual.parquet      # MÃ©tricas anuales LATAM
â”œâ”€â”€ metrics_latam_period.parquet      # MÃ©tricas periodo LATAM
â”œâ”€â”€ metrics_country_annual.parquet    # MÃ©tricas anuales por paÃ­s
â”œâ”€â”€ metrics_country_period.parquet    # MÃ©tricas periodo por paÃ­s
â”œâ”€â”€ metrics_journal_annual.parquet    # MÃ©tricas anuales por revista
â””â”€â”€ metrics_journal_period.parquet    # MÃ©tricas periodo por revista
```

---

## âš¡ ComparaciÃ³n de Rendimiento

| Script | RAM Usada | Tiempo (3.7GB dataset) | NÃºcleos Usados |
|--------|-----------|------------------------|----------------|
| `precompute_metrics.py` | ~500 MB | 2-4 horas | 1 |
| `precompute_metrics_parallel.py` | ~8 GB | 10-30 min | Todos |
| `precompute_country_metrics.py` | ~2 GB | 30-60 min | 1 |

---

## ğŸ”§ Troubleshooting

### Error: "MemoryError" o "Killed"
**SoluciÃ³n**: Usa `precompute_metrics.py` (versiÃ³n chunk-based)

### Proceso muy lento en servidor
**SoluciÃ³n**: Verifica que estÃ©s usando `precompute_metrics_parallel.py`

### Solo necesito actualizar paÃ­ses
**SoluciÃ³n**: Usa `precompute_country_metrics.py` para ahorrar tiempo

---

## ğŸ“Š Monitoreo en Servidor

Para ver el uso de recursos mientras corre:
```bash
# En otra terminal
watch -n 2 'top -b -n 1 | head -20'

# O para ver solo Python
watch -n 2 'ps aux | grep python'
```
