# Revistas LATAM (An√°lisis Bibliom√©trico)

Sistema de recolecci√≥n y an√°lisis de datos bibliom√©tricos para revistas latinoamericanas indexadas, utilizando la API de OpenAlex.

## üöÄ Funcionalidades

- **Descarga Masiva**: Obtiene datos de miles de revistas latinoamericanas y sus art√≠culos.
- **Procesamiento Inteligente**: Calcula indicadores como FWCI (Field-Weighted Citation Impact), percentiles de citas, √çndice H, y m√°s.
- **Dashboard Interactivo**: Visualizaci√≥n de datos con Streamlit y Plotly.
  - An√°lisis por Regi√≥n, Pa√≠s y Revista.
  - Gr√°ficos de impacto, redes de colaboraci√≥n (futuro), y evoluci√≥n temporal.

## üõ†Ô∏è Instalaci√≥n

1.  **Clonar el repositorio**:
    ```bash
    git clone https://github.com/chilti/revistas_latam.git
    cd revistas_latam
    ```

2.  **Crear un entorno virtual** (recomendado):
    ```bash
    python -m venv .venv
    # Windows:
    .venv\Scripts\activate
    # Linux/Mac:
    source .venv/bin/activate
    ```

3.  **Instalar dependencias**:
    ```bash
    pip install -r requirements.txt
    ```

## üìä Uso

### 1. Recolecci√≥n de Datos
El script `data_collector.py` descarga la informaci√≥n desde OpenAlex.
*Nota: La primera ejecuci√≥n puede tardar varias horas dependiendo del volumen de datos.*

```bash
python src/data_collector.py
```
Esto generar√° archivos `.parquet` en la carpeta `data/`.

### 2. Precalcular Indicadores (Recomendado)
Despu√©s de descargar los art√≠culos, ejecuta el script de prec√°lculo para acelerar el dashboard.

#### Opci√≥n A: Script Optimizado Paralelo (Recomendado)
Para m√°quinas con m√∫ltiples cores y grandes vol√∫menes de datos:

```bash
python precompute_metrics_parallel_optimized.py
```

**Caracter√≠sticas**:
- ‚úÖ **Procesamiento paralelo**: Usa m√∫ltiples cores para acelerar el c√°lculo
- ‚úÖ **Procesamiento incremental**: Solo calcula m√©tricas para revistas/pa√≠ses nuevos
- ‚úÖ **Optimizado para memoria**: Procesa en chunks para evitar saturar la RAM
- ‚úÖ **Recuperaci√≥n de errores**: Contin√∫a donde se qued√≥ si falla

**Opciones**:
- `--force`: Recalcula todas las m√©tricas desde cero (ignora cache)

**Ejemplo**:
```bash
# Primera ejecuci√≥n - calcula todo
python precompute_metrics_parallel_optimized.py

# Ejecuciones posteriores - solo procesa lo nuevo
python precompute_metrics_parallel_optimized.py

# Forzar rec√°lculo completo
python precompute_metrics_parallel_optimized.py --force
```

**Documentaci√≥n detallada**:
- üìñ [Gu√≠a de C√°lculo de M√©tricas](METRICS_CALCULATION_GUIDE.md) - Explicaci√≥n detallada de c√≥mo se calcula cada m√©trica
- üìñ [Procesamiento Incremental](INCREMENTAL_PROCESSING.md) - C√≥mo funciona el modo incremental
- üìñ [Correcciones de C√°lculo](CALCULATION_FIXES.md) - Validaci√≥n de consistencia con script original

#### Opci√≥n B: Script Original (M√°s Simple)
Para datasets peque√±os o primera vez:

```bash
python precompute_metrics.py
```

**Opciones**:
- `--force`: Forzar rec√°lculo aunque exista cach√© v√°lido

---

**M√©tricas calculadas** (ambos scripts):

- FWCI (Field-Weighted Citation Impact)
- Percentiles de citas
- % Top 10% (art√≠culos altamente citados)
- % Art√≠culos en acceso abierto
- % Revistas indexadas en Scopus, CORE, DOAJ

Los resultados se guardan en `data/cache/` y el dashboard los cargar√° autom√°ticamente.

**Opciones:**
- `python precompute_metrics.py --force`: Forzar rec√°lculo aunque exista cach√© v√°lido

### 3. Ejecutar el Dashboard
Para visualizar los indicadores:

```bash
streamlit run dashboard.py
```

## üìÇ Estructura del Proyecto

- `dashboard.py`: Aplicaci√≥n principal (Streamlit).
- `precompute_metrics.py`: Script original para precalcular indicadores.
- `precompute_metrics_parallel.py`: Script paralelo b√°sico.
- `precompute_metrics_parallel_optimized.py`: Script optimizado con procesamiento incremental (recomendado).
- `src/`: M√≥dulos de l√≥gica.
  - `data_collector.py`: Interacci√≥n con API OpenAlex y guardado incremental.
  - `data_processor.py`: Limpieza y c√°lculo de KPIs generales.
  - `performance_metrics.py`: C√°lculo avanzado de m√©tricas (Normalizaci√≥n, Percentiles).
- `data/`: Almacenamiento de datos (ignorado en git por tama√±o).
  - `cache/`: M√©tricas precalculadas para carga r√°pida del dashboard.

### üìö Documentaci√≥n

- **[METRICS_CALCULATION_GUIDE.md](METRICS_CALCULATION_GUIDE.md)**: Gu√≠a completa y detallada de c√≥mo se calcula cada m√©trica
  - Definiciones de todas las m√©tricas
  - F√≥rmulas y ejemplos paso a paso
  - Proceso de c√°lculo paralelo
  - Validaci√≥n de resultados
  
- **[INCREMENTAL_PROCESSING.md](INCREMENTAL_PROCESSING.md)**: Documentaci√≥n del procesamiento incremental
  - C√≥mo funciona el modo incremental
  - Ventajas y casos de uso
  - Comparaci√≥n de rendimiento
  
- **[CALCULATION_FIXES.md](CALCULATION_FIXES.md)**: Validaci√≥n de consistencia con script original
  - Correcciones aplicadas
  - Verificaci√≥n de equivalencia


## üìù Notas
- Este proyecto utiliza `pyalex` para interactuar con OpenAlex.
- Los datos complejos se almacenan como cadenas JSON dentro de archivos Parquet para m√°xima compatibilidad.

---
Desarrollado para el an√°lisis de la ciencia en Latinoam√©rica. üåé
