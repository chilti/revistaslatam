# Gu√≠a de Ejecuci√≥n del Prec√°lculo de M√©tricas

## ‚ö†Ô∏è Problema Identificado

El script paralelo con 24-32 n√∫cleos **satura el servidor** y crea procesos zombies que no completan.

## ‚úÖ Soluci√≥n Implementada

**Configuraci√≥n actualizada: 50% de n√∫cleos (16 de 32)**

```python
# En precompute_metrics_parallel.py l√≠nea 202
num_cores = max(1, int(total_cores * 0.5))  # 50% = 16 n√∫cleos
```

## üöÄ C√≥mo Ejecutar Correctamente

### Opci√≥n 1: Escritorio Remoto (Recomendado para primera vez)
```bash
# Desde escritorio remoto
cd /mnt/expansion/desplegados/revistaslatam
python3 precompute_metrics_parallel.py
```

**Ventajas:**
- Ves el progreso en tiempo real
- Puedes monitorear recursos
- F√°cil de interrumpir si hay problemas

### Opci√≥n 2: Con nohup (Para dejar corriendo)
```bash
# Ejecutar en background
nohup python3 precompute_metrics_parallel.py > precompute.log 2>&1 &

# Ver progreso
tail -f precompute.log

# Ver PID del proceso
ps aux | grep precompute_metrics_parallel
```

### Opci√≥n 3: Con screen (M√°s flexible)
```bash
# Crear sesi√≥n
screen -S metrics

# Dentro de screen
python3 precompute_metrics_parallel.py

# Desconectar: Ctrl+A, luego D
# Reconectar: screen -r metrics
```

## üìä Tiempo Estimado (16 n√∫cleos)

- **Carga de datos**: ~30 segundos
- **LATAM**: ~15-20 segundos
- **Pa√≠ses (19)**: ~1-2 minutos
- **Revistas (7,715)**: ~10-20 minutos

**Total: 15-25 minutos**

## üîç Monitorear Recursos

En otra terminal SSH:

```bash
# Ver uso de CPU y RAM
htop

# O m√°s simple
top

# Ver procesos Python
watch -n 2 'ps aux | grep python | head -20'

# Ver uso de RAM
free -h
```

## ‚úÖ Verificar Archivos Generados

```bash
# Despu√©s de completar
ls -lh data/cache/

# Deber√≠as ver:
# metrics_latam_annual.parquet
# metrics_latam_period.parquet
# metrics_country_annual.parquet
# metrics_country_period.parquet
# metrics_journal_annual.parquet
# metrics_journal_period.parquet
```

## üõë Si Necesitas Detener el Proceso

```bash
# Encontrar PID
ps aux | grep precompute_metrics_parallel

# Matar proceso (reemplaza PID)
kill -9 <PID>

# Verificar que se detuvo
ps aux | grep precompute_metrics_parallel
```

## üîß Ajustar N√∫cleos Manualmente

Si 16 n√∫cleos a√∫n es mucho, edita l√≠nea 202:

```python
# 25% de n√∫cleos (8 de 32)
num_cores = max(1, int(total_cores * 0.25))

# 33% de n√∫cleos (10-11 de 32)
num_cores = max(1, int(total_cores * 0.33))
```

## üìù Notas Importantes

1. **Primera ejecuci√≥n**: Usa escritorio remoto para ver que todo funciona
2. **RAM suficiente**: 128 GB es m√°s que suficiente para los 3.7 GB de datos
3. **Disco externo**: El I/O puede ser lento, pero con datos en RAM no es problema
4. **Procesos zombies**: Si aparecen, mata el proceso principal y reinicia
5. **Archivos parciales**: Si se interrumpe, borra `data/cache/*` antes de reiniciar

## üéØ Recomendaci√≥n Final

**Para tu servidor (32 n√∫cleos, 128 GB RAM):**
- Usa **16 n√∫cleos (50%)** - Balance perfecto
- Ejecuta desde **escritorio remoto** la primera vez
- Tiempo total: **~20 minutos**
- Deja SSH disponible para monitoreo

Si 16 n√∫cleos a√∫n causa problemas, baja a 8 (25%).
